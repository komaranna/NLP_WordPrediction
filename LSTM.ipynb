{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\" Code snippets from \"\n",
    "\" https://www.codeproject.com/Articles/1237557/Two-Ways-to-Implement-LSTM-Network-using-Python-wi \"\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "class DataHandler:\n",
    "    def read_data(self, fname):\n",
    "        with open(fname) as f:\n",
    "            content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "        content = [content[i].split() for i in range(len(content))]\n",
    "        content = np.array(content)\n",
    "        content = np.reshape(content, [-1, ])\n",
    "        return content\n",
    "    \n",
    "    def build_datasets(self, words):\n",
    "        count = collections.Counter(words).most_common()\n",
    "        dictionary = dict()\n",
    "        for word, _ in count:\n",
    "            dictionary[word] = len(dictionary)\n",
    "        reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "        return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "class RNNGenerator:\n",
    "    def create_LSTM(self, inputs, weights, biases, seq_size, num_units):\n",
    "        # Reshape input to [1, sequence_size] and split it into sequences\n",
    "        inputs = tf.reshape(inputs, [-1, seq_size])\n",
    "        inputs = tf.split(inputs, seq_size, 1)\n",
    "    \n",
    "        # LSTM with 2 layers\n",
    "        rnn_model = rnn.MultiRNNCell([rnn.BasicLSTMCell(num_units),rnn.BasicLSTMCell(num_units)])\n",
    "    \n",
    "        # Generate prediction\n",
    "        outputs, states = rnn.static_rnn(rnn_model, inputs, dtype=tf.float32)\n",
    "    \n",
    "        return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class SessionRunner():\n",
    "    training_iters = 20000\n",
    "            \n",
    "    def __init__(self, optimizer, accuracy, cost, lstm, initilizer, writer):\n",
    "        self.optimizer = optimizer\n",
    "        self.accuracy = accuracy\n",
    "        self.cost = cost\n",
    "        self.lstm = lstm\n",
    "        self.initilizer = initilizer\n",
    "        self.writer = writer\n",
    "    \n",
    "    def run_session(self, x, y, n_input, dictionary, reverse_dictionary, training_data, test_data):\n",
    "        \n",
    "        with tf.Session() as session:\n",
    "            session.run(self.initilizer)\n",
    "            step = 0\n",
    "            offset = random.randint(0, n_input + 1)\n",
    "            acc_total = 0\n",
    "        \n",
    "            self.writer.add_graph(session.graph)\n",
    "        \n",
    "            while step < self.training_iters:\n",
    "                if offset > (len(training_data) - n_input - 1):\n",
    "                    offset = random.randint(0, n_input+1)\n",
    "        \n",
    "                sym_in_keys = [ [dictionary[ str(training_data[i])]] \n",
    "                                 for i in range(offset, offset+n_input) ]\n",
    "                sym_in_keys = np.reshape(np.array(sym_in_keys), [-1, n_input, 1])\n",
    "        \n",
    "                sym_out_onehot = np.zeros([len(dictionary)], dtype=float)\n",
    "                sym_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "                sym_out_onehot = np.reshape(sym_out_onehot,[1,-1])\n",
    "                \n",
    "                _, acc, loss, onehot_pred = session.run([self.optimizer, self.accuracy, \n",
    "                   self.cost, self.lstm], feed_dict={x: sym_in_keys, y: sym_out_onehot})\n",
    "                acc_total += acc\n",
    "                \n",
    "                if (step + 1) % 1000 == 0:\n",
    "                    print(\"Iteration = \" + str(step + 1) + \", Average Accuracy= \" + \n",
    "                                           \"{:.2f}%\".format(100*acc_total/1000))\n",
    "                    offset_t = -n_input\n",
    "                    sym_in_keys_test = [ [dictionary[ str(test_data[i])]] \n",
    "                                     for i in range(offset_t, offset_t+n_input) ]\n",
    "                    sym_in_keys_test = np.reshape(np.array(sym_in_keys_test), [-1, n_input, 1])\n",
    "\n",
    "                    sym_out_onehot_test = np.zeros([len(dictionary)], dtype=float)\n",
    "                    sym_out_onehot_test[dictionary[str(training_data[offset_t+n_input])]] = 1.0\n",
    "                    sym_out_onehot_test = np.reshape(sym_out_onehot_test,[1,-1])\n",
    "                    _, _, _, onehot_pred_test = session.run([self.optimizer, self.accuracy, \n",
    "                                                             self.cost, self.lstm], feed_dict={x: sym_in_keys_test, y: sym_out_onehot_test})\n",
    "                    print(np.argmax(onehot_pred_test))\n",
    "                    acc_total = 0\n",
    "                step += 1\n",
    "                offset += (n_input+1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    def run_session_open_ended(self, x, y, n_input, dictionary, reverse_dictionary, training_data, test_data):\n",
    "        \n",
    "        session = tf.Session()\n",
    "        session.run(self.initilizer)\n",
    "        step = 0\n",
    "        offset = random.randint(0, n_input + 1)\n",
    "        acc_total = 0\n",
    "\n",
    "        self.writer.add_graph(session.graph)\n",
    "\n",
    "        while step < self.training_iters:\n",
    "            if offset > (len(training_data) - n_input - 1):\n",
    "                offset = random.randint(0, n_input+1)\n",
    "\n",
    "            sym_in_keys = [ [dictionary[ str(training_data[i])]] \n",
    "                             for i in range(offset, offset+n_input) ]\n",
    "            sym_in_keys = np.reshape(np.array(sym_in_keys), [-1, n_input, 1])\n",
    "\n",
    "            sym_out_onehot = np.zeros([len(dictionary)], dtype=float)\n",
    "            sym_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "            sym_out_onehot = np.reshape(sym_out_onehot,[1,-1])\n",
    "\n",
    "            _, acc, loss, onehot_pred = session.run([self.optimizer, self.accuracy, \n",
    "               self.cost, self.lstm], feed_dict={x: sym_in_keys, y: sym_out_onehot})\n",
    "            acc_total += acc\n",
    "\n",
    "            if (step + 1) % 1000 == 0:\n",
    "                print(\"Iteration = \" + str(step + 1) + \", Average Accuracy= \" + \n",
    "                                       \"{:.2f}%\".format(100*acc_total/1000))\n",
    "                offset_t = -n_input\n",
    "                sym_in_keys_test = [ [dictionary[ str(test_data[i])]] \n",
    "                                 for i in range(offset_t, offset_t+n_input) ]\n",
    "                sym_in_keys_test = np.reshape(np.array(sym_in_keys_test), [-1, n_input, 1])\n",
    "\n",
    "                sym_out_onehot_test = np.zeros([len(dictionary)], dtype=float)\n",
    "                sym_out_onehot_test[dictionary[str(training_data[offset_t+n_input])]] = 1.0\n",
    "                sym_out_onehot_test = np.reshape(sym_out_onehot_test,[1,-1])\n",
    "                onehot_pred_test = session.run([self.lstm], feed_dict={x: sym_in_keys_test, y: sym_out_onehot_test})\n",
    "                print(np.argmax(onehot_pred_test))\n",
    "                acc_total = 0\n",
    "            step += 1\n",
    "            offset += (n_input+1)\n",
    "            \n",
    "        return session, [self.optimizer, self.accuracy, self.cost, self.lstm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_path = '/output/tensorflow/'\n",
    "writer = tf.summary.FileWriter(log_path)\n",
    "\n",
    "# Load and prepare data\n",
    "data_handler = DataHandler()\n",
    "\n",
    "training_data =  flatten(data_handler.read_data('Ch1.tex'))\n",
    "#test_data =  data_handler.read_data('test.txt')\n",
    "test_data = training_data\n",
    "\n",
    "dictionary, reverse_dictionary = data_handler.build_datasets(training_data)\n",
    "\n",
    "# TensorFlow Graph input\n",
    "n_input = 5\n",
    "n_units = 512\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, len(dictionary)])\n",
    "\n",
    "# RNN output weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_units, len(dictionary)]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([len(dictionary)]))\n",
    "}\n",
    "\n",
    "rnn_generator = RNNGenerator()\n",
    "lstm = rnn_generator.create_LSTM(x, weights, biases, n_input, n_units)\n",
    "\n",
    "# Loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=lstm, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(lstm,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "initilizer = tf.global_variables_initializer()\n",
    "\n",
    "session_runner = SessionRunner(optimizer, accuracy, cost, lstm, initilizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1000, Average Accuracy= 4.00%\n",
      "1\n",
      "Iteration = 2000, Average Accuracy= 6.10%\n",
      "8\n",
      "Iteration = 3000, Average Accuracy= 5.00%\n",
      "1\n",
      "Iteration = 4000, Average Accuracy= 6.20%\n",
      "3\n",
      "Iteration = 5000, Average Accuracy= 5.60%\n",
      "3\n",
      "Iteration = 6000, Average Accuracy= 5.30%\n",
      "5\n",
      "Iteration = 7000, Average Accuracy= 6.00%\n",
      "1\n",
      "Iteration = 8000, Average Accuracy= 6.00%\n",
      "1\n",
      "Iteration = 9000, Average Accuracy= 6.40%\n",
      "1\n",
      "Iteration = 10000, Average Accuracy= 6.80%\n",
      "2\n",
      "Iteration = 11000, Average Accuracy= 6.00%\n",
      "1\n",
      "Iteration = 12000, Average Accuracy= 5.20%\n",
      "0\n",
      "Iteration = 13000, Average Accuracy= 6.10%\n",
      "1\n",
      "Iteration = 14000, Average Accuracy= 6.60%\n",
      "1\n",
      "Iteration = 15000, Average Accuracy= 5.70%\n",
      "0\n",
      "Iteration = 16000, Average Accuracy= 6.80%\n",
      "8\n",
      "Iteration = 17000, Average Accuracy= 5.70%\n",
      "7\n",
      "Iteration = 18000, Average Accuracy= 5.70%\n",
      "8\n",
      "Iteration = 19000, Average Accuracy= 6.80%\n",
      "7\n",
      "Iteration = 20000, Average Accuracy= 6.20%\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "session_runner = SessionRunner(optimizer, accuracy, cost, lstm, initilizer, writer)\n",
    "saved_sess, sess_parameters = session_runner.run_session_open_ended(x, y, n_input, dictionary, reverse_dictionary, \n",
    "                                                   training_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data =  data_handler.read_data('test3.txt')\n",
    "offset_t = -n_input\n",
    "sym_in_keys_test = [ [dictionary[ str(test_data[i])]] \n",
    "                 for i in range(offset_t, offset_t+n_input) ]\n",
    "sym_in_keys_test = np.reshape(np.array(sym_in_keys_test), [-1, n_input, 1])\n",
    "\n",
    "sym_out_onehot_test = np.zeros([len(dictionary)], dtype=float)\n",
    "sym_out_onehot_test[dictionary[str(training_data[offset_t+n_input])]] = 1.0\n",
    "sym_out_onehot_test = np.reshape(sym_out_onehot_test,[1,-1])\n",
    "#_, _, _, onehot_pred_test = saved_sess.run(sess_parameters, feed_dict={x: sym_in_keys_test, y: sym_out_onehot_test})\n",
    "onehot_pred_test = saved_sess.run(sess_parameters[-1], feed_dict={x: sym_in_keys_test, y: sym_out_onehot_test})\n",
    "print(reverse_dictionary[np.argmax(onehot_pred_test)])\n",
    "print(np.argmax(onehot_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "test_data =  data_handler.read_data('prompt.txt')\n",
    "offset_t = -n_input\n",
    "sym_in_keys_test = [ [dictionary[ str(test_data[i])]] \n",
    "                 for i in range(offset_t, offset_t+n_input) ]\n",
    "sym_in_keys_test = np.reshape(np.array(sym_in_keys_test), [-1, n_input, 1])\n",
    "#Printing (end of) prompt\n",
    "for j in range(n_input): print(reverse_dictionary[sym_in_keys_test[0][j][0]])\n",
    "\n",
    "sym_out_onehot_test = np.zeros([len(dictionary)], dtype=float)\n",
    "sym_out_onehot_test[dictionary[str(training_data[offset_t+n_input])]] = 1.0\n",
    "sym_out_onehot_test = np.reshape(sym_out_onehot_test,[1,-1])\n",
    "\n",
    "#First prediction\n",
    "onehot_pred_test = saved_sess.run(sess_parameters[-1], feed_dict={x: sym_in_keys_test, y: sym_out_onehot_test})\n",
    "prediction = np.argmax(onehot_pred_test)\n",
    "print(reverse_dictionary[prediction])\n",
    "\n",
    "#Continued predictions\n",
    "for i in range(iterations):\n",
    "    sym_in_keys_new = np.append(sym_in_keys_test,prediction)\n",
    "    sym_in_keys_test = np.reshape(np.array(sym_in_keys_new[-n_input:]), [-1, n_input, 1])\n",
    "    \n",
    "    #This can be whatever\n",
    "    sym_out_onehot_test = np.zeros([len(dictionary)], dtype=float)\n",
    "    sym_out_onehot_test[dictionary[str(training_data[offset_t+n_input])]] = 1.0\n",
    "    sym_out_onehot_test = np.reshape(sym_out_onehot_test,[1,-1])\n",
    "\n",
    "    #Further predictions\n",
    "    onehot_pred_test = saved_sess.run(sess_parameters[-1], feed_dict={x: sym_in_keys_test, y: sym_out_onehot_test})\n",
    "    prediction = np.argmax(onehot_pred_test)\n",
    "    print(reverse_dictionary[np.argmax(onehot_pred_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = [list(['\\\\chapter{Overview}']), list([]),\n",
    " list(['The', 'concept', 'of', 'quantum', 'computers', 'was', 'first', 'introduced', 'by', 'Richard', 'Feynman', '\\\\cite{Feynman82},', 'in', 'the', 'context', 'of', 'using', 'a', 'quantum', 'system', 'to', 'simulate', 'quantum', 'phenomena.', 'He', 'believed', 'that', \"``there's\", 'plenty', 'of', 'room', 'at', 'the', \"bottom''\", '\\\\cite{Feynman60},', 'and', 'he', 'was', 'right.', 'Since', 'then,', 'the', 'field', 'of', 'quantum', 'computation', 'underwent', 'an', 'enormous', 'development:', 'from', 'when', 'David', 'Deutsch', 'demonstrated', 'the', 'power', 'of', '``parallel', 'computing', 'with', \"qubits''\", '\\\\cite{Deutsch85},', 'when', 'Peter', 'Shor', 'constructed', 'his', 'factoring', 'algorithm', '\\\\cite{Shor94},', 'to', 'the', 'first', 'concept', 'of', 'quantum', 'error-correcting', 'codes', '(also', 'pioneered', 'by', 'Shor', '\\\\cite{CS96,Steane96,Gottesman97}),', 'all', 'the', 'way', 'to', 'today,', 'when', 'several', 'research', 'groups,', 'both', 'academic', 'and', 'commercial,', 'already', 'have', 'or', 'are', 'on', 'the', 'brink', 'of', 'realizing', 'working', 'quantum', 'computers', '\\\\cite{MRN+17,Castelvecchi17}.']),\n",
    " list([])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    merged = []\n",
    "    for el in l:\n",
    "        merged = merged + el\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
